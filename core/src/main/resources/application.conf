
grafana {
  server = "localhost"
  port = 3000
}
# Configuration of Kafka broker to subscribe for events
kafka {
  # true if use local kafka server
  # false otherwise
  # if true, then setting of brokers below is ignored and set to that of KafkaLocalServer
  localserver = true

  brokers = "localhost:9092"
  topic = "killrweather.raw"
  group = "killrweather.group"
}

# Configuration entries in this stanza are passed directly to the spark configuration builder
spark {
  master = "local[2]"
  cleaner.ttl = 2 hours
  checkpoint.dir = "./checkpoints/"

  cassandra {
    connection.host = "localhost"
    connection.port = 9042
  }

}
streaming {
  batchInterval = 5 seconds
  checkpointDir = "./checkpoints/"
}

influx {
  server = "localhost"
  port = 8086
  user = "root"
  password = "root"
  enabled = false
}

grpc.ingester.client {
  host = "localhost"
  port = 50051
}


# Application specific configuration
app {
  cassandra {
    keyspace = "isd_weather_data"
    tableRaw = "raw_weather_data"
    tableDailyTemp = "daily_aggregate_temperature"
    tableDailyWind = "daily_aggregate_windspeed"
    tableDailyPressure = "daily_aggregate_pressure"
    tableDailyPrecip = "daily_aggregate_precip"

    tableMonthlyTemp = "monthly_aggregate_temperature"
    tableMonthlyWind = "monthly_aggregate_windspeed"
    tableMonthlyPressure = "monthly_aggregate_pressure"
    tableMonthlyPrecip = "monthly_aggregate_precip"

    tableSky = "sky_condition_lookup"
    tableStations = "weather_station"
  }

  influx {
    database = "weather"
    retentionPolicy = "default"
  }

  data {
    loadPath = "./data/load"
    fileExtension = ".csv.gz"
  }
}
# Properties for akka.kafka.ProducerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.producer {
  # Tuning parameter of how many sends that can run in parallel.
  parallelism = 100

  # Duration to wait for `KafkaConsumer.close` to finish.
  close-timeout = 60s

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
  eos-commit-interval = 100ms

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients {
  }
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}